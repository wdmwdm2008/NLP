{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:/study/AI Training and Jobs/NLP_CV_Course/datasource-master/export_sql_1558435/sqlResult_1558435.csv\"\n",
    "stop_words_path = \"C:/study/AI Training and Jobs/NLP_CV_Course/datasource-master/\"\n",
    "cleaned_data_path = \"C:/study/AI Training and Jobs/NLP_CV_Course/week_7/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(csv_path, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.dropna(subset=[\"content\", \"source\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(cleaned_data_path + 'jieba_data.txt', 'r', encoding='UTF-8') as f:\n",
    "#     lines = f.readlines()\n",
    "# news_pos = news[news['source'].str.contains(\"新华社\")]\n",
    "# news_neg = news[news['source'].str.contains(\"新华社\") == 0]\n",
    "# news_pos = news_pos.sample(len(news_neg))\n",
    "# news_sampled = news_pos.append(news_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus's shape is  (87052,)\n",
      "['nba', 'nn', 'nnn', 'nnnum', 'nnum', 'num', 'numnum', '一个', '一些', '一名', '一带', '一次', '一直', '一起', '一路', '万元', '上海', '不仅', '不同', '不少', '不断', '不是', '不能', '专业', '专家', '世界', '业务', '中国', '中心', '为了', '主场', '主席', '主要', '举办', '举行', '之一', '之后', '习近平', '了解', '事件', '二线', '互联网', '交流', '产业', '产品', '人们', '人员', '人民', '人民币', '亿元', '今年', '介绍', '他们', '代表', '以上', '以及', '以来', '价格', '企业', '会议', '传统', '位于', '体育', '作为', '作品', '使用', '促进', '俄罗斯', '保护', '信息', '健康', '全国', '全球', '全面', '公司', '公开赛', '共享', '共同', '关于', '关注', '关系', '其中', '其他', '具有', '内容', '冠军', '决定', '决赛', '出现', '分别', '创新', '利用', '制造', '加强', '包括', '北京', '区域', '历史', '去年', '参与', '参加', '双方', '发展', '发布', '发现', '发生', '取得', '叙利亚', '可以', '可能', '台湾', '合作', '同时', '启动', '品牌', '因为', '国内', '国家', '国际', '图表', '地区', '地方', '城市', '基础', '基金', '增加', '增长', '外代', '大学', '夺冠', '如何', '如果', '媒体', '存在', '学习', '学校', '学生', '孩子', '安全', '完成', '实施', '实现', '宣布', '对于', '就是', '展示', '工作', '工程', '已经', '巴黎', '市场', '希望', '带来', '帮助', '平台', '广州', '庆祝', '建立', '建设', '开始', '开展', '开放', '当地', '当天', '当日', '形成', '影响', '影片', '很多', '得到', '德国', '总统', '情况', '意大利', '成为', '成功', '成立', '我们', '我国', '战略', '战胜', '戛纳', '打造', '技术', '投资', '报告', '报道', '拍摄', '持续', '指出', '按照', '接受', '推动', '推进', '提供', '提出', '提升', '提高', '支持', '改革', '政府', '政策', '教育', '数据', '文化', '新华', '新华社', '新疆', '新闻', '方式', '方面', '旅游', '日本', '日电', '时装周', '时间', '显示', '晋级', '最后', '最大', '最终', '有关', '有限公司', '服务', '期间', '未来', '机制', '机构', '来自', '标准', '根据', '模式', '欧新', '欧洲', '正在', '正式', '此次', '死亡', '比赛', '水平', '江苏', '汽车', '没有', '法国', '法新', '活动', '游客', '澳大利亚', '照片', '特别', '特朗普', '环境', '现在', '现场', '球员', '生产', '生态', '生活', '用户', '由于', '电影', '监管', '目前', '目标', '相关', '看到', '研究', '社会', '科技', '积极', '管理', '篮球', '精神', '系统', '组织', '经济', '继续', '综合', '网球', '网络', '美国', '群众', '联合', '联赛', '能力', '能够', '自己', '英国', '英超', '获得', '行业', '行动', '表示', '要求', '规划', '规定', '规模', '解决', '计划', '认为', '记者', '设计', '调查', '资源', '资金', '赛季', '超过', '足球', '路透', '达到', '过程', '近年来', '近日', '还是', '还有', '这一', '这个', '这些', '这是', '这样', '这种', '进一步', '进入', '进行', '选手', '选择', '通过', '造成', '部分', '部门', '重点', '重要', '金融', '铁路', '银行', '锦标赛', '问题', '随着', '集团', '需求', '需要', '非常', '韩国', '项目', '预计', '领域', '风险', '首次', '首都', '香港']\n",
      "input of X's shape is  (87052, 350)\n",
      "train_data's shape is (87052, 350)\n"
     ]
    }
   ],
   "source": [
    "with open(cleaned_data_path + 'jieba_data.txt', 'r', encoding='UTF-8') as f:\n",
    "    lines = f.readlines()\n",
    "corpus = pd.Series(lines)\n",
    "print(\"corpus's shape is \", corpus.shape)\n",
    "vectorizer = TfidfVectorizer(max_features = 350, stop_words = [])\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"input of X's shape is \", X.shape)\n",
    "train_data = X.toarray()\n",
    "print(\"train_data's shape is {}\".format(train_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data's shape is (87052,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n",
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sourceMapping = {}\n",
    "for index, label in enumerate(set(news['source'])):\n",
    "    if label == \"新华社\":\n",
    "        sourceMapping['新华社'] = 1\n",
    "    else:\n",
    "        sourceMapping[label] = 0\n",
    "news['source'] = news['source'].map(sourceMapping)\n",
    "test_data = news['source']\n",
    "print(\"test_data's shape is {}\".format(test_data.shape))\n",
    "train_input, test_input, train_output, test_output = train_test_split(train_data, test_data, test_size=0.2, random_state=42)\n",
    "x_arr_train = train_input\n",
    "x_arr_test = test_input\n",
    "y_arr_train = train_output.as_matrix()\n",
    "y_arr_test = test_output.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### performance evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_evaluation(clf):\n",
    "#     print(\"model's score is {}\".format(clf.score(x_arr_test, y_arr_test)))\n",
    "    y_arr_test_pred = clf.predict(x_arr_test)\n",
    "    print(\"precision is {}\".format(precision_score(y_arr_test, y_arr_test_pred)))\n",
    "    print(\"recall score is {}\".format(recall_score(y_arr_test, y_arr_test_pred)))\n",
    "    print(\"f1 is {}\".format(f1_score(y_arr_test, y_arr_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction with Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.9943319226118501\n",
      "recall score is 0.835046966235085\n",
      "f1 is 0.9077549330757555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_arr_train[1:45000,:], y_arr_train[1:45000])\n",
    "performance_evaluation(gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.9911919396742919\n",
      "recall score is 0.9927646610814927\n",
      "f1 is 0.9919776770143006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=1,max_depth=30, random_state=0)\n",
    "clf.fit(x_arr_train, y_arr_train)\n",
    "performance_evaluation(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consuming time is 15.594910499000036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "start = time.clock()\n",
    "clf = SVC(gamma='auto', random_state=42, max_iter=500, kernel ='linear')\n",
    "clf.fit(x_arr_train[1:10000], y_arr_train[1:10000])\n",
    "elapse = time.clock() - start\n",
    "print(\"consuming time is {}\".format(elapse))\n",
    "performance_evaluation(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
